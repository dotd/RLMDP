{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding dynamically layers:\n",
    "https://discuss.pytorch.org/t/dynamically-add-or-delete-layers/10447/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig:\n",
      "[('a', 1), ('b', 2), ('c', 3), ('d', 4)]\n",
      "transposed:\n",
      "[('a', 'b', 'c', 'd'), (1, 2, 3, 4)]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is zip, *zip for transposing a matrix...\n",
    "'''\n",
    "orig = [('a', 1), ('b', 2), ('c', 3), ('d', 4)]\n",
    "print(\"orig:\")\n",
    "print(orig)\n",
    "vec = zip(*orig)\n",
    "print(\"transposed:\")\n",
    "print(list(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "Sequential(\n",
      "  (0): Embedding(3, 2)\n",
      ")\n",
      "Variable containing:\n",
      " 0.5000  0.5000\n",
      " 0.0000  1.0000\n",
      " 1.0000  0.0000\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is a working example of embedding layer. \n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "N, D_in, H, D_out = 3, 2, 2, 1\n",
    "\n",
    "x = Variable(torch.LongTensor([2,0,1]))\n",
    "\n",
    "# Embedding layer\n",
    "# Taken from https://discuss.pytorch.org/t/can-we-use-pre-trained-word-embeddings-for-weight-initialization-in-nn-embedding/1222\n",
    "embed = nn.Embedding(N, D_in)\n",
    "base = np.array([[0,1],[1,0],[0.5,0.5]])\n",
    "embed.weight.data.copy_(torch.from_numpy(base))\n",
    "# make it constant \n",
    "embed.weight.requires_grad = False\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    embed,\n",
    ")\n",
    "print(\"The model:\")\n",
    "print(model)\n",
    "\n",
    "# Continue, make the parameters constant\n",
    "# parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "y_pred = model(x)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 1\n",
       " 2\n",
       "[torch.IntTensor of size 3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "base = np.identity(3)\n",
    "idx = range(2)\n",
    "base[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Can we approximate some function with NN?\n",
    "import numpy as np\n",
    "x = np.linspace(0,10,1000)\n",
    "y = np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.01000984  0.02001868  0.03002552  0.04002934  0.05002916\n",
      "  0.06002396  0.07001275  0.07999452  0.08996827  0.09993302  0.10988774\n",
      "  0.11983146  0.12976317  0.13968188  0.14958659  0.15947632  0.16935006\n",
      "  0.17920684  0.18904566  0.19886554  0.20866549  0.21844453  0.22820168\n",
      "  0.23793597  0.24764642  0.25733206  0.26699191  0.276625    0.28623038\n",
      "  0.29580708  0.30535414  0.3148706   0.32435552  0.33380793  0.3432269\n",
      "  0.35261147  0.36196071  0.37127369  0.38054946  0.3897871   0.39898569\n",
      "  0.4081443   0.41726201  0.42633791  0.4353711   0.44436066  0.45330569\n",
      "  0.46220531  0.47105861  0.47986471  0.48862273  0.49733179  0.50599102\n",
      "  0.51459954  0.52315651  0.53166105  0.54011232  0.54850948  0.55685167\n",
      "  0.56513807  0.57336784  0.58154016  0.58965421  0.59770917  0.60570425\n",
      "  0.61363863  0.62151153  0.62932216  0.63706972  0.64475345  0.65237258\n",
      "  0.65992634  0.66741398  0.67483474  0.68218788  0.68947267  0.69668838\n",
      "  0.70383427  0.71090964  0.71791378  0.72484599  0.73170556  0.73849182\n",
      "  0.74520409  0.75184168  0.75840394  0.76489021  0.77129983  0.77763218\n",
      "  0.7838866   0.79006248  0.7961592   0.80217614  0.8081127   0.81396829\n",
      "  0.81974232  0.82543421  0.8310434   0.83656931  0.84201141  0.84736913\n",
      "  0.85264195  0.85782933  0.86293076  0.86794572  0.87287371  0.87771425\n",
      "  0.88246684  0.887131    0.89170627  0.8961922   0.90058833  0.90489422\n",
      "  0.90910944  0.91323357  0.91726619  0.9212069   0.92505531  0.92881103\n",
      "  0.93247368  0.9360429   0.93951832  0.94289961  0.94618642  0.94937842\n",
      "  0.9524753   0.95547674  0.95838244  0.96119211  0.96390547  0.96652224\n",
      "  0.96904217  0.97146501  0.9737905   0.97601842  0.97814855  0.98018066\n",
      "  0.98211456  0.98395005  0.98568695  0.98732509  0.9888643   0.99030442\n",
      "  0.99164532  0.99288685  0.9940289   0.99507134  0.99601408  0.99685702\n",
      "  0.99760007  0.99824317  0.99878624  0.99922924  0.99957211  0.99981483\n",
      "  0.99995736  0.9999997   0.99994184  0.99978379  0.99952556  0.99916717\n",
      "  0.99870867  0.9981501   0.99749152  0.99673299  0.99587459  0.9949164\n",
      "  0.99385852  0.99270105  0.99144412  0.99008785  0.98863237  0.98707782\n",
      "  0.98542438  0.98367219  0.98182145  0.97987232  0.97782501  0.97567973\n",
      "  0.97343668  0.97109609  0.9686582   0.96612325  0.9634915   0.9607632\n",
      "  0.95793864  0.95501809  0.95200185  0.94889022  0.94568351  0.94238205\n",
      "  0.93898615  0.93549618  0.93191246  0.92823537  0.92446527  0.92060254\n",
      "  0.91664757  0.91260074  0.90846248  0.90423319  0.89991329  0.89550322\n",
      "  0.89100343  0.88641436  0.88173646  0.87697022  0.87211611  0.86717461\n",
      "  0.86214622  0.85703145  0.8518308   0.84654479  0.84117397  0.83571886\n",
      "  0.83018001  0.82455797  0.81885332  0.81306662  0.80719845  0.80124939\n",
      "  0.79522006  0.78911104  0.78292295  0.77665642  0.77031206  0.76389052\n",
      "  0.75739244  0.75081847  0.74416927  0.7374455   0.73064784  0.72377697\n",
      "  0.71683358  0.70981836  0.70273201  0.69557526  0.68834881  0.68105338\n",
      "  0.67368972  0.66625855  0.65876062  0.65119668  0.6435675   0.63587383\n",
      "  0.62811645  0.62029613  0.61241365  0.60446981  0.59646541  0.58840124\n",
      "  0.58027811  0.57209684  0.56385824  0.55556315  0.54721239  0.5388068\n",
      "  0.53034722  0.5218345   0.51326949  0.50465305  0.49598605  0.48726935\n",
      "  0.47850382  0.46969035  0.46082982  0.45192311  0.44297112  0.43397474\n",
      "  0.42493488  0.41585245  0.40672834  0.39756348  0.38835878  0.37911517\n",
      "  0.36983358  0.36051492  0.35116015  0.34177018  0.33234597  0.32288847\n",
      "  0.3133986   0.30387734  0.29432562  0.28474442  0.27513468  0.26549738\n",
      "  0.25583347  0.24614393  0.23642973  0.22669183  0.21693122  0.20714888\n",
      "  0.19734578  0.1875229   0.17768124  0.16782177  0.15794548  0.14805337\n",
      "  0.13814643  0.12822564  0.118292    0.10834651  0.09839017  0.08842397\n",
      "  0.0784489   0.06846598  0.05847619  0.04848055  0.03848005  0.02847569\n",
      "  0.01846848  0.00845942 -0.00155049 -0.01156024 -0.02156884 -0.03157527\n",
      " -0.04157854 -0.05157764 -0.06157158 -0.07155935 -0.08153994 -0.09151237\n",
      " -0.10147562 -0.11142871 -0.12137064 -0.1313004  -0.141217   -0.15111946\n",
      " -0.16100677 -0.17087795 -0.18073201 -0.19056796 -0.20038482 -0.21018159\n",
      " -0.21995731 -0.22971099 -0.23944165 -0.24914832 -0.25883002 -0.26848579\n",
      " -0.27811466 -0.28771566 -0.29728783 -0.30683021 -0.31634185 -0.32582179\n",
      " -0.33526908 -0.34468278 -0.35406195 -0.36340563 -0.37271291 -0.38198284\n",
      " -0.39121449 -0.40040694 -0.40955928 -0.41867057 -0.42773992 -0.4367664\n",
      " -0.44574912 -0.45468718 -0.46357968 -0.47242573 -0.48122444 -0.48997494\n",
      " -0.49867633 -0.50732776 -0.51592836 -0.52447726 -0.53297361 -0.54141656\n",
      " -0.54980525 -0.55813886 -0.56641654 -0.57463746 -0.58280081 -0.59090576\n",
      " -0.5989515  -0.60693723 -0.61486214 -0.62272545 -0.63052635 -0.63826408\n",
      " -0.64593786 -0.65354691 -0.66109048 -0.66856781 -0.67597814 -0.68332075\n",
      " -0.69059488 -0.69779982 -0.70493484 -0.71199922 -0.71899227 -0.72591327\n",
      " -0.73276153 -0.73953637 -0.74623711 -0.75286308 -0.75941361 -0.76588805\n",
      " -0.77228575 -0.77860606 -0.78484836 -0.79101202 -0.79709642 -0.80310095\n",
      " -0.80902501 -0.814868   -0.82062935 -0.82630847 -0.83190479 -0.83741776\n",
      " -0.84284682 -0.84819143 -0.85345104 -0.85862515 -0.86371322 -0.86871474\n",
      " -0.87362922 -0.87845616 -0.88319509 -0.88784551 -0.89240698 -0.89687902\n",
      " -0.9012612  -0.90555308 -0.90975421 -0.91386419 -0.91788261 -0.92180905\n",
      " -0.92564312 -0.92938445 -0.93303265 -0.93658737 -0.94004823 -0.94341491\n",
      " -0.94668706 -0.94986435 -0.95294646 -0.95593309 -0.95882393 -0.9616187\n",
      " -0.96431712 -0.96691891 -0.96942382 -0.97183159 -0.97414198 -0.97635477\n",
      " -0.97846973 -0.98048664 -0.98240531 -0.98422555 -0.98594716 -0.98756998\n",
      " -0.98909385 -0.99051862 -0.99184413 -0.99307026 -0.99419689 -0.99522389\n",
      " -0.99615118 -0.99697865 -0.99770623 -0.99833384 -0.99886141 -0.9992889\n",
      " -0.99961626 -0.99984346 -0.99997048 -0.9999973  -0.99992392 -0.99975034\n",
      " -0.9994766  -0.9991027  -0.9986287  -0.99805464 -0.99738057 -0.99660656\n",
      " -0.9957327  -0.99475906 -0.99368575 -0.99251287 -0.99124054 -0.98986889\n",
      " -0.98839806 -0.98682819 -0.98515943 -0.98339197 -0.98152597 -0.97956163\n",
      " -0.97749913 -0.97533868 -0.97308051 -0.97072484 -0.9682719  -0.96572194\n",
      " -0.96307521 -0.96033199 -0.95749254 -0.95455715 -0.95152611 -0.94839974\n",
      " -0.94517833 -0.94186221 -0.93845173 -0.93494721 -0.93134901 -0.92765748\n",
      " -0.92387301 -0.91999597 -0.91602674 -0.91196573 -0.90781333 -0.90356998\n",
      " -0.89923609 -0.8948121  -0.89029844 -0.88569558 -0.88100397 -0.87622409\n",
      " -0.87135641 -0.86640142 -0.86135962 -0.85623151 -0.8510176  -0.84571842\n",
      " -0.84033451 -0.83486639 -0.82931462 -0.82367975 -0.81796235 -0.81216299\n",
      " -0.80628225 -0.80032073 -0.79427901 -0.7881577  -0.78195742 -0.77567879\n",
      " -0.76932244 -0.762889   -0.75637913 -0.74979346 -0.74313266 -0.7363974\n",
      " -0.72958836 -0.72270621 -0.71575164 -0.70872536 -0.70162807 -0.69446047\n",
      " -0.68722329 -0.67991724 -0.67254307 -0.66510151 -0.65759331 -0.65001922\n",
      " -0.64238    -0.63467641 -0.62690923 -0.61907923 -0.6111872  -0.60323392\n",
      " -0.59522021 -0.58714685 -0.57901466 -0.57082446 -0.56257706 -0.55427329\n",
      " -0.54591398 -0.53749997 -0.5290321  -0.52051123 -0.5119382  -0.50331387\n",
      " -0.49463911 -0.48591479 -0.47714179 -0.46832097 -0.45945322 -0.45053944\n",
      " -0.44158052 -0.43257735 -0.42353083 -0.41444188 -0.4053114  -0.39614031\n",
      " -0.38692953 -0.37767997 -0.36839258 -0.35906827 -0.34970798 -0.34031265\n",
      " -0.33088322 -0.32142064 -0.31192585 -0.3023998  -0.29284346 -0.28325777\n",
      " -0.2736437  -0.26400222 -0.25433428 -0.24464085 -0.23492291 -0.22518144\n",
      " -0.2154174  -0.20563177 -0.19582554 -0.18599969 -0.1761552  -0.16629307\n",
      " -0.15641427 -0.14651979 -0.13661064 -0.12668779 -0.11675226 -0.10680502\n",
      " -0.09684708 -0.08687944 -0.0769031  -0.06691904 -0.05692829 -0.04693183\n",
      " -0.03693066 -0.0269258  -0.01691823 -0.00690898  0.00310097  0.01311061\n",
      "  0.02311894  0.03312495  0.04312764  0.05312601  0.06311905  0.07310577\n",
      "  0.08308517  0.09305624  0.10301799  0.11296941  0.12290952  0.13283731\n",
      "  0.14275178  0.15265196  0.16253684  0.17240543  0.18225675  0.19208981\n",
      "  0.20190362  0.2116972   0.22146956  0.23121974  0.24094675  0.25064961\n",
      "  0.26032736  0.26997903  0.27960364  0.28920024  0.29876786  0.30830554\n",
      "  0.31781233  0.32728728  0.33672943  0.34613784  0.35551157  0.36484968\n",
      "  0.37415123  0.38341529  0.39264093  0.40182723  0.41097327  0.42007813\n",
      "  0.42914089  0.43816066  0.44713652  0.45606758  0.46495294  0.47379172\n",
      "  0.48258302  0.49132596  0.50001968  0.50866329  0.51725594  0.52579676\n",
      "  0.53428489  0.54271949  0.5510997   0.5594247   0.56769364  0.5759057\n",
      "  0.58406006  0.59215589  0.60019239  0.60816875  0.61608417  0.62393786\n",
      "  0.63172904  0.63945691  0.64712071  0.65471967  0.66225303  0.66972002\n",
      "  0.67711992  0.68445196  0.69171543  0.69890958  0.70603371  0.71308709\n",
      "  0.72006902  0.7269788   0.73381574  0.74057914  0.74726835  0.75388267\n",
      "  0.76042146  0.76688406  0.77326981  0.77957808  0.78580824  0.79195966\n",
      "  0.79803173  0.80402383  0.80993537  0.81576576  0.82151441  0.82718074\n",
      "  0.83276419  0.8382642   0.84368021  0.84901169  0.85425809  0.8594189\n",
      "  0.8644936   0.86948167  0.87438263  0.87919597  0.88392121  0.88855789\n",
      "  0.89310553  0.89756369  0.90193191  0.90620976  0.9103968   0.91449263\n",
      "  0.91849682  0.92240898  0.92622871  0.92995564  0.93358938  0.93712958\n",
      "  0.94057589  0.94392794  0.94718542  0.95034798  0.95341533  0.95638714\n",
      "  0.95926312  0.96204298  0.96472645  0.96731325  0.96980313  0.97219584\n",
      "  0.97449113  0.97668877  0.97878856  0.98079027  0.9826937   0.98449867\n",
      "  0.986205    0.9878125   0.98932103  0.99073043  0.99204056  0.99325128\n",
      "  0.99436249  0.99537405  0.99628589  0.99709789  0.99780999  0.9984221\n",
      "  0.99893418  0.99934616  0.99965801  0.99986969  0.99998119  0.99999249\n",
      "  0.99990359  0.9997145   0.99942524  0.99903584  0.99854633  0.99795677\n",
      "  0.99726722  0.99647774  0.99558841  0.99459933  0.99351059  0.9923223\n",
      "  0.99103458  0.98964756  0.98816137  0.98657617  0.98489212  0.98310938\n",
      "  0.98122814  0.97924858  0.97717089  0.9749953   0.97272201  0.97035125\n",
      "  0.96788327  0.9653183   0.96265661  0.95989847  0.95704414  0.95409391\n",
      "  0.95104809  0.94790697  0.94467087  0.94134012  0.93791504  0.93439599\n",
      "  0.93078331  0.92707737  0.92327853  0.91938718  0.91540371  0.91132852\n",
      "  0.90716201  0.9029046   0.89855673  0.89411881  0.88959131  0.88497468\n",
      "  0.88026936  0.87547585  0.87059461  0.86562614  0.86057094  0.85542951\n",
      "  0.85020236  0.84489002  0.83949303  0.83401192  0.82844724  0.82279955\n",
      "  0.81706941  0.81125741  0.80536412  0.79939013  0.79333605  0.78720247\n",
      "  0.78099002  0.77469931  0.76833097  0.76188565  0.75536399  0.74876664\n",
      "  0.74209427  0.73534754  0.72852712  0.72163371  0.71466799  0.70763067\n",
      "  0.70052243  0.69334401  0.68609611  0.67877947  0.67139481  0.66394288\n",
      "  0.65642443  0.6488402   0.64119095  0.63347746  0.6257005   0.61786084\n",
      "  0.60995927  0.60199658  0.59397358  0.58589106  0.57774983  0.56955071\n",
      "  0.56129452  0.5529821   0.54461426  0.53619185  0.52771572  0.51918671\n",
      "  0.51060568  0.50197348  0.49329099  0.48455907  0.4757786   0.46695046\n",
      "  0.45807552  0.44915469  0.44018886  0.43117891  0.42212577  0.41303032\n",
      "  0.40389349  0.39471619  0.38549934  0.37624387  0.36695069  0.35762075\n",
      "  0.34825497  0.3388543   0.32941967  0.31995204  0.31045234  0.30092154\n",
      "  0.29136059  0.28177045  0.27215207  0.26250642  0.25283447  0.24313718\n",
      "  0.23341553  0.2236705   0.21390305  0.20411417  0.19430484  0.18447604\n",
      "  0.17462875  0.16476397  0.15488267  0.14498586  0.13507452  0.12514965\n",
      "  0.11521223  0.10526327  0.09530377  0.08533471  0.07535711  0.06537195\n",
      "  0.05538024  0.04538299  0.03538119  0.02537584  0.01536795  0.00535852\n",
      " -0.00465145 -0.01466095 -0.02466899 -0.03467455 -0.04467663 -0.05467424\n",
      " -0.06466637 -0.07465203 -0.0846302  -0.09459989 -0.1045601  -0.11450984\n",
      " -0.1244481  -0.13437389 -0.14428622 -0.15418409 -0.16406652 -0.1739325\n",
      " -0.18378105 -0.19361119 -0.20342193 -0.21321229 -0.22298128 -0.23272793\n",
      " -0.24245127 -0.2521503  -0.26182408 -0.27147162 -0.28109195 -0.29068412\n",
      " -0.30024717 -0.30978013 -0.31928205 -0.32875198 -0.33818897 -0.34759207\n",
      " -0.35696034 -0.36629285 -0.37558865 -0.38484682 -0.39406643 -0.40324656\n",
      " -0.41238627 -0.42148467 -0.43054084 -0.43955386 -0.44852284 -0.45744688\n",
      " -0.46632509 -0.47515657 -0.48394043 -0.49267581 -0.50136182 -0.5099976\n",
      " -0.51858227 -0.52711499 -0.53559488 -0.54402111]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.24993822, 0.22593797, 0.        , 0.        ,\n",
       "        0.2275677 , 0.        , 0.        , 0.29655611, 0.        ]),\n",
       " array([ 0.        ,  0.95008842, -0.15135721,  0.        ,  0.        ,\n",
       "         1.86755799,  0.        ,  0.        , -0.97727788,  0.        ]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_random_sparse_vector(X, B, random_state):\n",
    "    # initialize the size\n",
    "    P_vec = np.zeros(shape=(X,))\n",
    "    # put in the first places 0:B all the random variables.\n",
    "    P_vec[0:B] = random_state.uniform(low=0, high=1.0, size=(B,))\n",
    "\n",
    "    # initialize the size\n",
    "    R_vec = np.zeros(shape=(X,))\n",
    "    # put in the first places 0:B all the random variables.\n",
    "    R_vec[0:B] = random_state.normal(size=(B,))\n",
    "\n",
    "\n",
    "    P_vec[0:B] = P_vec[0:B] / np.sum(P_vec[0:B])\n",
    "    idx = random_state.permutation([x for x in range(X)])\n",
    "    P_vec = P_vec[idx]\n",
    "    R_vec = R_vec[idx]\n",
    "    return P_vec, R_vec\n",
    "\n",
    "get_random_sparse_vector(10,4,np.random.RandomState(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0, 1]\n",
      "[0, 1, 2]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3, 4]\n",
      "[1, 2, 3, 4, 5]\n",
      "[2, 3, 4, 5, 6]\n",
      "[3, 4, 5, 6, 7]\n",
      "[4, 5, 6, 7, 8]\n",
      "[5, 6, 7, 8, 9]\n",
      "[6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "a = deque(maxlen = 5)\n",
    "\n",
    "for i in range(11):\n",
    "    a.append(i)\n",
    "    print(list(a))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-310552754404>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-310552754404>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    import ...samplers as s\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload\n",
    "import ..samplers as s\n",
    "s = s.BasicSampler(5,[\"a\",\"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function zeros in module numpy.core.multiarray:\n",
      "\n",
      "zeros(...)\n",
      "    zeros(shape, dtype=float, order='C')\n",
      "    \n",
      "    Return a new array of given shape and type, filled with zeros.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    shape : int or sequence of ints\n",
      "        Shape of the new array, e.g., ``(2, 3)`` or ``2``.\n",
      "    dtype : data-type, optional\n",
      "        The desired data-type for the array, e.g., `numpy.int8`.  Default is\n",
      "        `numpy.float64`.\n",
      "    order : {'C', 'F'}, optional\n",
      "        Whether to store multidimensional data in C- or Fortran-contiguous\n",
      "        (row- or column-wise) order in memory.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        Array of zeros with the given shape, dtype, and order.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    zeros_like : Return an array of zeros with shape and type of input.\n",
      "    ones_like : Return an array of ones with shape and type of input.\n",
      "    empty_like : Return an empty array with shape and type of input.\n",
      "    ones : Return a new array setting values to one.\n",
      "    empty : Return a new uninitialized array.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.zeros(5)\n",
      "    array([ 0.,  0.,  0.,  0.,  0.])\n",
      "    \n",
      "    >>> np.zeros((5,), dtype=int)\n",
      "    array([0, 0, 0, 0, 0])\n",
      "    \n",
      "    >>> np.zeros((2, 1))\n",
      "    array([[ 0.],\n",
      "           [ 0.]])\n",
      "    \n",
      "    >>> s = (2,2)\n",
      "    >>> np.zeros(s)\n",
      "    array([[ 0.,  0.],\n",
      "           [ 0.,  0.]])\n",
      "    \n",
      "    >>> np.zeros((2,), dtype=[('x', 'i4'), ('y', 'i4')]) # custom dtype\n",
      "    array([(0, 0), (0, 0)],\n",
      "          dtype=[('x', '<i4'), ('y', '<i4')])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "help(np.zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 2), (3, 4), (5, 6)]\n",
      "[(1, 3, 5), (2, 4, 6)]\n",
      "[[1, 3, 5], [2, 4, 6]]\n"
     ]
    }
   ],
   "source": [
    "a = [(1,2),(3,4),(5,6)]\n",
    "print(a)\n",
    "aa = list(zip(*a))\n",
    "print(aa)\n",
    "bb = [list(x) for x in aa]\n",
    "print(bb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 0.026< > 0.135<\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vec = np.array([0.02648392, 0.13453])\n",
    "def show_numpy_vector_nicely(vec, separator = \" \",):\n",
    "    return separator.join([\">{:6.3f}<\".format(x) for x in vec])\n",
    "\n",
    "print(show_numpy_vector_nicely(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.01398019e-04, 1.80983209e-02, 4.00000000e+00])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: abs(x)**2\n",
    "f(np.array([-0.02648392, -0.13453, -2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
